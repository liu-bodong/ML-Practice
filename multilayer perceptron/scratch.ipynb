{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = [transforms.ToTensor()]\n",
    "\n",
    "trans = transforms.Compose(trans)\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=True, transform=trans, download=False)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=False, transform=trans, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                        num_workers=8)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                        num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "num_hiddens = 256\n",
    "\n",
    "W1 = nn.Parameter(torch.randn(\n",
    "    num_inputs, num_hiddens, requires_grad=True) * 0.01)\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\n",
    "W2 = nn.Parameter(torch.randn(\n",
    "    num_hiddens, num_outputs, requires_grad=True) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n",
    "\n",
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca31f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    zeros = torch.zeros_like(X)\n",
    "    return torch.max(zeros, X)\n",
    "\n",
    "def net(X):\n",
    "    X = X.reshape(-1, num_inputs)\n",
    "    H = relu(X@W1 + b1)\n",
    "    return relu(H@W2 + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = y_pred.argmax(axis=1)\n",
    "    cmp = y_pred.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "    metric = d2l.Accumulator(2) # count (1) num of accurate predictions and (2) total num of predictions\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_epoch(net, train_iter, criterion, optimizer):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.train()\n",
    "    # count (1) total training loss, (2) total training accuracy, and (3) num of samples\n",
    "    metric = d2l.Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        y_pred = net(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metric.add(float(loss.sum()), accuracy(y_pred, y), y.numel())\n",
    "        \n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def train(net, train_iter, test_iter, criterion, num_epochs, optimizer):\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1], legend=['train loss', 'train acc', 'test acc'],)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch(net, train_iter, criterion, optimizer)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0206cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(params, lr=lr)\n",
    "\n",
    "train(net, train_iter, test_iter, criterion, epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "        'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot' ]\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763426d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, test_oter, n=8):\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    true_labels = get_fashion_mnist_labels(y)\n",
    "    pred_labels = get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    show_images(\n",
    "        X[0:n].reshape(-1, 28, 28), 1, n, titles=titles[0:n]    \n",
    "    )\n",
    "    \n",
    "predict(net, test_iter, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf74232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
